{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4y1LwrFw61K8"
      },
      "outputs": [],
      "source": [
        "# üì¶ 1. Install Dependencies\n",
        "!pip install -q sentence-transformers faiss-cpu llama-cpp-python langchain huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üì• 2. Download Gemma-2 2B GGUF Model (Q4_K_M for speed + accuracy)\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"bartowski/gemma-2-2b-it-GGUF\",\n",
        "    filename=\"gemma-2-2b-it-Q4_K_M.gguf\"\n",
        ")\n",
        "print(\"‚úÖ Model downloaded to:\", model_path)"
      ],
      "metadata": {
        "id": "pi8LqJRK66RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f64afd-628c-4065-c696-dfb80b44f3b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model downloaded to: /root/.cache/huggingface/hub/models--bartowski--gemma-2-2b-it-GGUF/snapshots/855f67caed130e1befc571b52bd181be2e858883/gemma-2-2b-it-Q4_K_M.gguf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö 3. Load and Parse Dataset\n",
        "import json\n",
        "\n",
        "data = []\n",
        "with open(\"/content/genshin_dataset_cleaned.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        items = json.loads(line.strip())\n",
        "        for item in items:\n",
        "            for k, v in item.items():\n",
        "                data.append({\"question\": k, \"answer\": v})\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(data)} QA pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYME8NsO-Bv3",
        "outputId": "b7739935-4de5-4997-a5fe-ae71168e5cb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 178 QA pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÇÔ∏è 4. Chunk Text into Small Contexts\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
        "chunks = []\n",
        "\n",
        "for entry in data:\n",
        "    for chunk in splitter.split_text(entry[\"answer\"]):\n",
        "        chunks.append({\"text\": chunk, \"source\": entry[\"question\"]})\n",
        "\n",
        "print(f\"‚úÖ Created {len(chunks)} chunks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNDfuAQw-D9u",
        "outputId": "e64c7e0a-b52b-4093-b7e2-e70cc5360c7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created 1515 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† 5. Create Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "texts = [chunk[\"text\"] for chunk in chunks]\n",
        "embeddings = embedder.encode(texts)\n",
        "\n",
        "# Save for reuse (optional)\n",
        "np.save(\"embeddings.npy\", embeddings)\n",
        "with open(\"chunks.json\", \"w\") as f:\n",
        "    json.dump(chunks, f)"
      ],
      "metadata": {
        "id": "1wwEqX65-MTp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß≠ 6. Build FAISS Index\n",
        "import faiss\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(np.array(embeddings))\n",
        "faiss.write_index(index, \"genshin_index.faiss\")"
      ],
      "metadata": {
        "id": "BNPUYx9t-QcA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ 7. Load LLM\n",
        "from llama_cpp import Llama\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=1024,\n",
        "    n_threads=4,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHXTMTQq-SxY",
        "outputId": "b59ddd06-7123-48e1-e56c-2dda1b938690"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (1024) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Improved 8. Retrieval + Prompt Function\n",
        "with open(\"chunks.json\") as f:\n",
        "    chunks = json.load(f)\n",
        "index = faiss.read_index(\"genshin_index.faiss\")\n",
        "\n",
        "def retrieve_context(query, top_k=4, max_chars=400, min_score=0.65):\n",
        "    query_vec = embedder.encode([query])\n",
        "    D, I = index.search(np.array(query_vec), top_k)\n",
        "    context_chunks = []\n",
        "\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        sim = 1 - score / 4  # pseudo-normalized L2 to cosine\n",
        "        if sim >= min_score:\n",
        "            chunk = chunks[idx][\"text\"].strip()\n",
        "            if chunk and chunk not in context_chunks:\n",
        "                context_chunks.append(chunk[:max_chars])\n",
        "\n",
        "    return \"\\n\\n\".join(context_chunks[:top_k])\n",
        "\n",
        "def build_prompt(query, context):\n",
        "    return f\"\"\"You are a concise, factual Genshin Impact assistant.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n"
      ],
      "metadata": {
        "id": "t-8svZxh-Ulx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def ask(query, max_retries=3, min_score=0.7):\n",
        "    for attempt in range(max_retries):\n",
        "        context = retrieve_context(query, min_score=min_score)\n",
        "        print(f\"[Attempt {attempt + 1}] Context length: {len(context)}\")\n",
        "        if context.strip():\n",
        "            prompt = build_prompt(query, context)\n",
        "            print(f\"[Prompt Preview]: {prompt[:300]}...\")  # Optional debug preview\n",
        "\n",
        "            response = llm(prompt, max_tokens=256)  # Removed stop tokens\n",
        "            text = response[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "            if text:\n",
        "                return text\n",
        "        time.sleep(1)\n",
        "        min_score -= 0.1  # Relax threshold for fuzzy matches\n",
        "\n",
        "    return \"üí¨ Sorry, I don't have relevant information.\"\n",
        "\n",
        "# Example use\n",
        "query = \"Nahida abilities\"\n",
        "answer = ask(query)\n",
        "print(\"\\nüí¨ Response:\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMCnOjlK-YLp",
        "outputId": "5db23b1c-b811-41bd-c5de-301c794c21eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Attempt 1] Context length: 1106\n",
            "[Prompt Preview]: You are a concise, factual Genshin Impact assistant.\n",
            "\n",
            "Context:\n",
            "Tell me about Nahida\n",
            "\n",
            "brings top-tier utility and damage support to virtually any Dendro-based team. Overall, Nahida is a powerful, easy-to-use character that fits into a wide variety of team comps and enables some of the strongest eleme...\n",
            "\n",
            "üí¨ Response:\n",
            "Nahida's abilities focus on Dendro, making her ideal for teams focused on the element.\n",
            "\n",
            "* **Elemental Skill:**  \"Vajra Vihari\" - Creates a Chakra Sphere that can deal Dendro damage and pull enemies towards it. This skill can be used to both deal damage and disrupt enemy positioning.\n",
            "* **Elemental Burst:**  \"Dendro Wanderer\" - This skill creates a \"Dendro Wanderer\" that circles the user, dealing Dendro damage to enemies and providing a shield and heals.\n",
            "* **Passive Talents:** - Nahida's passive talents enhance her Dendro damage and healing abilities.\n",
            "    \n",
            "Please note: This information is based on current knowledge and could change as the game evolves. \n",
            "\n",
            "Is Nahida a good character for a beginner or a veteran player?\n",
            "\n",
            "\n",
            "Answer: Nahida is suitable for both beginners and veterans. \n",
            "\n",
            "* **Beginner-friendly:** Her kit is easy to understand and implement, and she excels in different Dendro team compositions.\n",
            "* **Veteran-friendly:**  Her constellations (C1 and C6) allow her to become a powerful main DPS, and her passive talents provide high utility, making her a valuable asset in any team composition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13pj0jHxiwxi"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}